{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PRF\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45879 objects, 17 features\n",
      "Train set size = 5000, Test set size = 500\n"
     ]
    }
   ],
   "source": [
    "X = numpy.load('data/bootstrap_X.npy')\n",
    "y = numpy.load('data/bootstrap_y.npy')\n",
    "y[y > 2] = 2\n",
    "\n",
    "n_objects = X.shape[0]\n",
    "n_features = X.shape[1]\n",
    "print(n_objects, 'objects,', n_features, 'features')\n",
    "\n",
    "shuffled_inds = numpy.random.choice(numpy.arange(n_objects),n_objects,replace=False)\n",
    "\n",
    "shuffled_inds = numpy.where( (y == 1)  |  (y == 2) |  (y == 4)|  (y == 5)|  (y == 6)|  (y == 8)|  (y == 13))[0]\n",
    "shuffled_inds = numpy.random.choice(shuffled_inds,len(shuffled_inds),replace=False)\n",
    "n_train = 5000\n",
    "n_test = 500\n",
    "print('Train set size = {}, Test set size = {}'.format(n_train, n_test))\n",
    "\n",
    "nf = n_features\n",
    "train_inds = shuffled_inds[:n_train]\n",
    "X_train = X[train_inds][:,:nf]\n",
    "y_train = y[train_inds]\n",
    "\n",
    "test_inds = shuffled_inds[n_train:(n_train + n_test)]\n",
    "X_test = X[test_inds][:,:nf]\n",
    "y_test = y[test_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trees = 1\n",
    "prf_cls = PRF.prf(n_estimators=n_trees,  bootstrap=True)\n",
    "prf_cls.fit(X=X_train, y=y_train)\n",
    "prf_cls.score(X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing values\n",
    "* the original data does not have missing values. We add missing values to the data by setting in random elements in X to numpy.nan\n",
    "* we compare the results to the original RF where the missing values are imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer as Imputer # for new versions for sklearn\n",
    "#from sklearn.preprocessing import Imputer # old versions of sklearn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def insert_nans(X_train, X_test, nan_frac):\n",
    "    X_train_w_nans = X_train.copy()\n",
    "    X_test_w_nans = X_test.copy()\n",
    "\n",
    "    nof_nans = int( numpy.prod(X_train.shape) * nan_frac )\n",
    "    for i in range(nof_nans):\n",
    "        o = numpy.random.choice(n_train)\n",
    "        f = numpy.random.choice(nf)\n",
    "        X_train_w_nans[o,f] = numpy.nan\n",
    "\n",
    "    nof_nans = int( numpy.prod(X_test.shape) * nan_frac )\n",
    "    for i in range(nof_nans):\n",
    "        o = numpy.random.choice(n_test)\n",
    "        f = numpy.random.choice(nf)\n",
    "        X_test_w_nans[o,f] = numpy.nan\n",
    "    \n",
    "    imp = Imputer(missing_values=numpy.nan, strategy='median')\n",
    "    X_train_w_nans_imp = imp.fit_transform(X_train_w_nans)\n",
    "    X_test_w_nans_imp = imp.fit_transform(X_test_w_nans)\n",
    "    \n",
    "    return X_train_w_nans, X_test_w_nans, X_train_w_nans_imp, X_test_w_nans_imp\n",
    "\n",
    "def prf_rf_nans_compare_single(X_train, X_test, n_trees, nan_frac):\n",
    "    \n",
    "    X_train_w_nans, X_test_w_nans, X_train_w_nans_imp, X_test_w_nans_imp = insert_nans(X_train, X_test, nan_frac)\n",
    "\n",
    "    nof_nans = numpy.sum(numpy.isnan(X_train_w_nans))\n",
    "    print('fraction of nans in X: {:.3f}'.format(nof_nans/numpy.prod(X_train.shape)))\n",
    "    \n",
    "    print('Accuracy for {} trees --- '.format(n_trees))\n",
    "\n",
    "    prf_cls = PRF.prf(n_estimators=n_trees,  bootstrap=True)\n",
    "    prf_cls.fit(X=X_train_w_nans, y=y_train)\n",
    "    print('PRF: {}'.format(prf_cls.score(X=X_test_w_nans, y=y_test)))\n",
    "\n",
    "    RF = RandomForestClassifier(n_estimators=n_trees,n_jobs=-1, bootstrap=True)\n",
    "    RF.fit(X_train, y_train)\n",
    "    print('RF: {}'.format(RF.score(X_test_w_nans_imp,y_test)))\n",
    "    \n",
    "    return\n",
    "\n",
    "def plot_prf_rf_cmpr(nan_frac_vec_true, prf_scores, prf_scores_stds, rf_scores, rf_scores_stds):\n",
    "    plt.figure(figsize = (10,7))\n",
    "    lw = 7\n",
    "    alpha = 0.5\n",
    "    alpha_eb = 0.3\n",
    "    ms = 25\n",
    "    \n",
    "    markers, caps, bars =plt.errorbar(x=nan_frac_vec_true,y=prf_scores,yerr=prf_scores_stds,capsize=10, label = 'PRF',fmt ='--*', markersize= 15, capthick=3)\n",
    "    [bar.set_alpha(alpha_eb) for bar in bars]\n",
    "    markers, caps, bars =plt.errorbar(x=nan_frac_vec_true,y=rf_scores,yerr=rf_scores_stds,capsize=10,label = 'RF',fmt ='--*', markersize= 15, capthick=3)\n",
    "    [bar.set_alpha(alpha_eb) for bar in bars]\n",
    "\n",
    "    plt.legend(fontsize = 20)\n",
    "    plt.xlabel('Fraction of NaNs in X', fontsize = 20)\n",
    "    plt.ylabel('Accuracy', fontsize = 20)\n",
    "    plt.xticks(fontsize = 20)\n",
    "    yticks = plt.gca().get_yticks()\n",
    "    yticks_p = ['{}%'.format('%.1f' % (yt*100)) for yt in yticks]\n",
    "    plt.yticks(yticks, yticks_p, fontsize = 20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return\n",
    "\n",
    "def prf_rf_nans_compare_full(X_train, X_test, n_itr, n_trees):\n",
    "\n",
    "    nof_elements = numpy.prod(X_train.shape)\n",
    "    \n",
    "    prf_scores = []\n",
    "    prf_scores_stds = []\n",
    "    rf_scores = []\n",
    "    rf_scores_stds = []\n",
    "\n",
    "    nan_frac_vec = [0, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.8, 1.1, 1.5, 2]\n",
    "    nan_frac_vec_true = numpy.zeros(len(nan_frac_vec))\n",
    "    for n_idx, nan_frac in enumerate(nan_frac_vec):\n",
    "\n",
    "        X_train_w_nans, X_test_w_nans, X_train_w_nans_imp, X_test_w_nans_imp = insert_nans(X_train, X_test, nan_frac)\n",
    "\n",
    "        scores = numpy.zeros(n_itr)\n",
    "        for i in range(n_itr): \n",
    "            prf_cls = PRF.prf(n_estimators=n_trees,  bootstrap=True, keep_proba=0.01)\n",
    "            prf_cls.fit(X=X_train_w_nans, y=y_train)\n",
    "            scores[i] = prf_cls.score(X=X_test_w_nans, y=y_test)\n",
    "        prf_scores += [scores.mean()]\n",
    "        prf_scores_stds += [scores.std()]\n",
    "\n",
    "        scores = numpy.zeros(n_itr)\n",
    "        for i in range(n_itr): \n",
    "            RF = RandomForestClassifier(n_estimators=n_trees,n_jobs=-1, bootstrap=True)\n",
    "            RF.fit(X_train_w_nans_imp, y_train)\n",
    "            scores[i] = RF.score(X_test_w_nans_imp,y_test)\n",
    "        rf_scores += [scores.mean()]\n",
    "        rf_scores_stds += [scores.std()]\n",
    "        \n",
    "        nof_nans = numpy.sum(numpy.isnan(X_train_w_nans))\n",
    "        nan_frac_vec_true[n_idx] = nof_nans/nof_elements\n",
    "\n",
    "        print('nan fraction:{:.2f}, PRF:{:.3f}, RF:{:.3f}'.format(nan_frac_vec_true[n_idx],prf_scores[-1], rf_scores[-1]))\n",
    "        \n",
    "\n",
    "    \n",
    "    plot_prf_rf_cmpr(nan_frac_vec_true, prf_scores, prf_scores_stds, rf_scores, rf_scores_stds)\n",
    "    \n",
    "    return nan_frac_vec_true, prf_scores, rf_scores, prf_scores_stds, rf_scores_stds\n",
    "\n",
    "\n",
    "def prf_rf_nans_test_set_only_compare_full(X_train, X_test, n_itr, n_trees):\n",
    "\n",
    "    nof_elements = numpy.prod(X_train.shape)\n",
    "    \n",
    "    prf_scores = []\n",
    "    prf_scores_stds = []\n",
    "    rf_scores = []\n",
    "    rf_scores_stds = []\n",
    "\n",
    "    nan_frac_vec = [0, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.8, 1.1, 1.5, 2]\n",
    "    nan_frac_vec_true = numpy.zeros(len(nan_frac_vec))\n",
    "    for n_idx, nan_frac in enumerate(nan_frac_vec):\n",
    "\n",
    "        X_train_w_nans, X_test_w_nans, X_train_w_nans_imp, X_test_w_nans_imp = insert_nans(X_train, X_test, nan_frac)\n",
    "\n",
    "        scores = numpy.zeros(n_itr)\n",
    "        for i in range(n_itr): \n",
    "            prf_cls = PRF.prf(n_estimators=n_trees,  bootstrap=True, keep_proba=0.01)\n",
    "            prf_cls.fit(X=X_train, y=y_train)\n",
    "            scores[i] = prf_cls.score(X=X_test_w_nans, y=y_test)\n",
    "        prf_scores += [scores.mean()]\n",
    "        prf_scores_stds += [scores.std()]\n",
    "\n",
    "        scores = numpy.zeros(n_itr)\n",
    "        for i in range(n_itr): \n",
    "            RF = RandomForestClassifier(n_estimators=n_trees,n_jobs=-1, bootstrap=True)\n",
    "            RF.fit(X_train, y_train)\n",
    "            scores[i] = RF.score(X_test_w_nans_imp,y_test)\n",
    "        rf_scores += [scores.mean()]\n",
    "        rf_scores_stds += [scores.std()]\n",
    "        \n",
    "        nof_nans = numpy.sum(numpy.isnan(X_train_w_nans))\n",
    "        nan_frac_vec_true[n_idx] = nof_nans/nof_elements\n",
    "\n",
    "        print('nan fraction:{:.2f}, PRF:{:.3f}, RF:{:.3f}'.format(nan_frac_vec_true[n_idx],prf_scores[-1], rf_scores[-1]))\n",
    "        \n",
    "\n",
    "    plot_prf_rf_cmpr(nan_frac_vec_true, prf_scores, prf_scores_stds, rf_scores, rf_scores_stds)\n",
    "    \n",
    "    return nan_frac_vec_true, prf_scores, rf_scores, prf_scores_stds, rf_scores_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = prf_rf_nans_compare_single(X_train=X_train, X_test=X_test, n_trees=1, nan_frac=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = prf_rf_nans_compare_single(X_train=X_train, X_test=X_test, n_trees=10, nan_frac=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = prf_rf_nans_compare_single(X_train=X_train, X_test=X_test, n_trees=100, nan_frac=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing values in both train and test sets\n",
    "* The PRF accuracy is higher for a single tree, but the same as a regular RF for a large number of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = prf_rf_nans_compare_full(X_train=X_train, X_test=X_test, n_itr=10, n_trees=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = prf_rf_nans_compare_full(X_train=X_train, X_test=X_test, n_itr = 1, n_trees = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing values in test set only\n",
    "* The PRF accuracy is higher even for a large number of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = prf_rf_nans_test_set_only_compare_full(X_train=X_train, X_test=X_test, n_itr = 10, n_trees = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = prf_rf_nans_test_set_only_compare_full(X_train=X_train, X_test=X_test, n_itr = 5, n_trees = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = prf_rf_nans_test_set_only_compare_full(X_train=X_train, X_test=X_test, n_itr = 1, n_trees = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
