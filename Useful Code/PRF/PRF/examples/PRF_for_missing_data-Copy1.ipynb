{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PRF\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy\n",
    "from sklearn.impute import SimpleImputer as Imputer # for new versions for sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.33453338  0.3817734   0.19323093 ... -0.81191589  0.19067206\n",
      "   0.84772759]\n",
      " [ 0.32742773  0.35012285  0.17785153 ... -0.85643206  0.19620735\n",
      "   0.85023905]\n",
      " [ 0.39173798  0.32019704  0.17513842 ...  0.23618577  0.20204299\n",
      "   0.79843681]\n",
      " ...\n",
      " [ 0.403697    0.27038462  0.12964029 ...  0.89465122  0.1941173\n",
      "   0.77770493]\n",
      " [ 0.25029907  0.33824084  0.20026945 ...  0.8638979   0.14645717\n",
      "   0.82934586]\n",
      " [ 0.27610644  0.34        0.16186233 ... -0.52845195  0.15704813\n",
      "   0.83015366]]\n",
      "[5 1 4 ... 1 5 1]\n",
      "2.34630222977833\n",
      "2.584966902039068\n",
      "[2 1 2 ... 1 2 1]\n",
      "45879 objects, 17 features\n",
      "Shuffled Indices:  [ 6690 21266  7081 ... 13535 25108 44330]\n",
      "45879\n",
      "Y Cut Shuffled Indices:  [    0     1     2 ... 45876 45877 45878]\n",
      "45879\n",
      "Re-Shuffled Indices?  [ 6965 11798  6789 ... 43515  5566 11678]\n",
      "Train set size = 10000, Test set size = 1000\n"
     ]
    }
   ],
   "source": [
    "X = numpy.load('data/bootstrap_X.npy')\n",
    "y = numpy.load('data/bootstrap_y.npy')\n",
    "print(X)\n",
    "print(y)\n",
    "print(numpy.mean(y))\n",
    "print(numpy.std(y))\n",
    "y[y > 2] = 2\n",
    "print(y)\n",
    "\n",
    "n_objects = X.shape[0]\n",
    "n_features = X.shape[1]\n",
    "print(n_objects, 'objects,', n_features, 'features')\n",
    "\n",
    "shuffled_inds = numpy.random.choice(numpy.arange(n_objects),n_objects,replace=False)\n",
    "print(\"Shuffled Indices: \", shuffled_inds)\n",
    "print(len(shuffled_inds))\n",
    "shuffled_inds = numpy.where( (y == 1)  |  (y == 2) |  (y == 4)|  (y == 5)|  (y == 6)|  (y == 8)|  (y == 13))[0]\n",
    "print(\"Y Cut Shuffled Indices: \", shuffled_inds)\n",
    "print(len(shuffled_inds))\n",
    "shuffled_inds = numpy.random.choice(shuffled_inds,len(shuffled_inds),replace=False)\n",
    "print(\"Re-Shuffled Indices? \", shuffled_inds)\n",
    "n_train = 10000\n",
    "n_test = 1000\n",
    "print('Train set size = {}, Test set size = {}'.format(n_train, n_test))\n",
    "\n",
    "nf = n_features\n",
    "train_inds = shuffled_inds[:n_train]\n",
    "X_train = X[train_inds][:,:nf]\n",
    "y_train = y[train_inds]\n",
    "\n",
    "test_inds = shuffled_inds[n_train:(n_train + n_test)]\n",
    "X_test = X[test_inds][:,:nf]\n",
    "y_test = y[test_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.823"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_trees = 100\n",
    "prf_cls = PRF.prf(n_estimators=n_trees,  bootstrap=True)\n",
    "prf_cls.fit(X=X_train, y=y_train)\n",
    "prf_cls.score(X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.823 [array([ 0.   ,  0.005,  0.008, -0.006,  0.005,  0.002,  0.006,  0.006,\n",
      "        0.001,  0.026,  0.016, -0.002,  0.009,  0.107,  0.01 ,  0.011,\n",
      "        0.007]), array([-0.002,  0.009,  0.009, -0.002,  0.003,  0.001,  0.014,  0.01 ,\n",
      "        0.008,  0.028,  0.022,  0.   ,  0.015,  0.116,  0.007,  0.008,\n",
      "        0.003]), array([ 0.006,  0.009,  0.003, -0.001,  0.012,  0.004,  0.008,  0.01 ,\n",
      "        0.01 ,  0.024,  0.022, -0.003,  0.003,  0.1  ,  0.007,  0.014,\n",
      "        0.   ]), array([ 0.002,  0.011,  0.012, -0.003,  0.003,  0.003,  0.014,  0.008,\n",
      "        0.007,  0.031,  0.027,  0.002,  0.004,  0.084,  0.007,  0.009,\n",
      "        0.002]), array([-0.002,  0.009,  0.006, -0.001,  0.009,  0.002,  0.014,  0.012,\n",
      "        0.008,  0.035,  0.022, -0.002,  0.009,  0.09 ,  0.012,  0.011,\n",
      "        0.001])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.0008,  0.0086,  0.0076, -0.0026,  0.0064,  0.0024,  0.0112,\n",
       "        0.0092,  0.0068,  0.0288,  0.0218, -0.001 ,  0.008 ,  0.0994,\n",
       "        0.0086,  0.0106,  0.0026])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from eli5.permutation_importance import get_score_importances\n",
    "\n",
    "# ... load data, define score function\n",
    "def score(X, y):\n",
    "    y_pred = predict(X)\n",
    "    return accuracy(y, y_pred)\n",
    "\n",
    "base_score, score_decreases = get_score_importances(prf_cls.score, X_test, y_test)\n",
    "print(base_score, score_decreases)\n",
    "feature_importances = numpy.mean(score_decreases, axis=0)\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aaron/anaconda3/envs/astroconda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/home/aaron/anaconda3/envs/astroconda/lib/python3.6/site-packages/sklearn/feature_selection/_base.py:81: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n",
      "  UserWarning)\n",
      "/home/aaron/anaconda3/envs/astroconda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/home/aaron/anaconda3/envs/astroconda/lib/python3.6/site-packages/sklearn/feature_selection/_base.py:81: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# ... load data\n",
    "imp = Imputer(missing_values=numpy.nan, strategy='median')\n",
    "X_train_w_nans_imp = imp.fit_transform(X_train)\n",
    "X,y = X_train_w_nans_imp, y_train\n",
    "\n",
    "perm = PermutationImportance(SVC(), cv=5)\n",
    "perm.fit(X, y)\n",
    "\n",
    "# perm.feature_importances_ attribute is now available, it can be used\n",
    "# for feature selection - let's e.g. select features which increase\n",
    "# accuracy by at least 0.05:\n",
    "sel = SelectFromModel(perm, threshold=0.05, prefit=True)\n",
    "X_trans = sel.transform(X)\n",
    "\n",
    "# It is possible to combine SelectFromModel and\n",
    "# PermutationImportance directly, without fitting\n",
    "# PermutationImportance first:\n",
    "sel = SelectFromModel(\n",
    "    PermutationImportance(SVC(), cv=5),\n",
    "    threshold=0.05,\n",
    ").fit(X, y)\n",
    "X_trans = sel.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(20000, 0), dtype=float64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['#cflvsc.sourceID', ' cflvsc.ra(J2000)', ' cflvsc.dec(J2000)',\n",
      "       ' cflvsc.gl(J2000)', ' cflvsc.gb(J2000)', ' cflvsc.zAperMag3',\n",
      "       ' cflvsc.zAperMag3Err', ' cflvsc.yAperMag3', ' cflvsc.yAperMag3Err',\n",
      "       ' cflvsc.jAperMag3', ' cflvsc.jAperMag3Err', ' cflvsc.hAperMag3',\n",
      "       ' cflvsc.hAperMag3Err', ' cflvsc.ksAperMag3', ' cflvsc.ksAperMag3Errs',\n",
      "       ' cflvsc.ksEMeanMagPawprint', ' cflvsc.ED', ' cflvsc.ExpRMS_Noise',\n",
      "       ' cflvsc.Ngoodmeasures', ' cflvsc.Xindex', ' cflvsc.Kfi2', ' cflvsc.L2',\n",
      "       ' cflvsc.Ncorrelation2', ' cflvsc.FAPcorrelation2',\n",
      "       ' cflvsc.FlagDataType', ' cflvsc.ebv', ' cflvsc.ebverr',\n",
      "       ' cflvsc.FreqKfi2', ' cflvsc.HeightKfi2toKfi2', ' cflvsc.HeightKfi2',\n",
      "       ' cflvsc.FreqLfl2', ' cflvsc.HeightKfi2toLfl2', ' cflvsc.HeightLfl2',\n",
      "       ' cflvsc.FreqLSG', ' cflvsc.HeightKfi2toLSG', ' cflvsc.HeightLSG',\n",
      "       ' cflvsc.FreqPDM', ' cflvsc.HeightKfi2toPDM', ' cflvsc.HeightPDM',\n",
      "       ' cflvsc.FreqSTR', ' cflvsc.HeightKfi2toSTR', ' cflvsc.HeightSTR',\n",
      "       ' cflvsc.Avar', ' cflvsc.FlagFbias6', ' cflvsc.FlagFbias7',\n",
      "       ' cflvsc.FlagNfreq', ' cflvsc.OtherNames', ' cflvsc.Period',\n",
      "       ' cflvsc.MainVarType', ' cflvsc.OtherVarType'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  EB        109479\n",
       "Spurious     28017\n",
       "  RR         27383\n",
       "  NSIN       11748\n",
       "  YSO         5757\n",
       "             ...  \n",
       "  BLAP           1\n",
       "  AM             1\n",
       "  UGSU           1\n",
       "  EXOR           1\n",
       "  AHB            1\n",
       "Name:  cflvsc.MainVarType, Length: 63, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "data = pd.read_csv('data/cflvsc_r01_crosssources.dat',na_values=-999)\n",
    "data = data[data[' cflvsc.MainVarType'] != '  Others']\n",
    "print(data.columns)\n",
    "\n",
    "data['zeroes'] = numpy.zeros(len(data[' cflvsc.Avar']))\n",
    "\n",
    "data.loc[data[' cflvsc.Ngoodmeasures'] < 40,' cflvsc.MainVarType'] = 'Spurious'\n",
    "data[' cflvsc.MainVarType'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EB           109479\n",
      "Spurious        28017\n",
      "  RR            27383\n",
      "  NSIN          11748\n",
      "  YSO            5757\n",
      "  iC             4208\n",
      "  E              2842\n",
      "  FKCOM          1565\n",
      "  X              1488\n",
      "  IR             1369\n",
      "  EW             1179\n",
      "  EA             1152\n",
      "  Radio           817\n",
      "  ISM             800\n",
      "  V*              756\n",
      "  PUL             701\n",
      "  SR              440\n",
      "  LPV             415\n",
      "  RGB             320\n",
      "  Planet          267\n",
      "  CW              262\n",
      "  PER             258\n",
      "  Microlens       196\n",
      "  TTS             190\n",
      "  M               156\n",
      "  DCEP            100\n",
      "  BE               87\n",
      "  N                62\n",
      "  ROT              54\n",
      "  CEP              46\n",
      "  WR               35\n",
      "  CV               33\n",
      "  DSCT             31\n",
      "  IN               30\n",
      "  UG               29\n",
      "  RV               28\n",
      "  TTau             27\n",
      "  APER             26\n",
      "  GRB              23\n",
      "Name:  cflvsc.MainVarType, dtype: int64\n",
      "[[14.76163  14.657574 14.700644 ...  0.804878  1.425342  0.      ]\n",
      " [      nan       nan       nan ...  0.952381  5.70632   0.      ]\n",
      " [      nan       nan       nan ...  0.904762  1.16128   0.      ]\n",
      " ...\n",
      " [      nan       nan       nan ...  0.913043 44.133835  1.918944]\n",
      " [      nan       nan       nan ...       nan       nan  2.10165 ]\n",
      " [      nan       nan       nan ...       nan       nan  2.104926]]\n",
      "['  RR' '  RR' '  RR' ... '  EA' 'Spurious' 'Spurious']\n",
      "202376 objects, 14 features\n",
      "Shuffled Indices:  [ 35121  72158  15133 ... 149190 173429  39189]\n",
      "202376\n",
      "Re-Shuffled Indices?  [184202 132853 140940 ... 111664 178139  20571]\n",
      "Train set size = 20000, Test set size = 2000\n"
     ]
    }
   ],
   "source": [
    "#Remove columns with too few variables in them\n",
    "\n",
    "counts = data[' cflvsc.MainVarType'].value_counts()\n",
    "valid = counts[counts > 20]\n",
    "print(valid)\n",
    "data = data[data[' cflvsc.MainVarType'].isin(valid.index.values)]\n",
    "\n",
    "for inverse_column in [' cflvsc.HeightKfi2',' cflvsc.HeightLfl2',' cflvsc.HeightLSG',' cflvsc.HeightPDM',\n",
    "        ' cflvsc.HeightSTR']:\n",
    "    columnName = inverse_column.replace(\" cflvsc.\",'Inverse')\n",
    "    data[columnName] = numpy.ones(len(data[inverse_column]))\n",
    "    data[columnName] = data[columnName].div(data[inverse_column])\n",
    "    \n",
    "    \n",
    "X=data[[' cflvsc.zAperMag3',\n",
    "       ' cflvsc.zAperMag3Err', ' cflvsc.yAperMag3', ' cflvsc.yAperMag3Err',\n",
    "       ' cflvsc.jAperMag3', ' cflvsc.jAperMag3Err', ' cflvsc.hAperMag3',\n",
    "       ' cflvsc.hAperMag3Err', ' cflvsc.ksAperMag3', ' cflvsc.ksAperMag3Errs',\n",
    "       ' cflvsc.ksEMeanMagPawprint', ' cflvsc.ED', ' cflvsc.ExpRMS_Noise',\n",
    "       ' cflvsc.Ngoodmeasures', ' cflvsc.Xindex', ' cflvsc.Kfi2', ' cflvsc.L2',\n",
    "       ' cflvsc.Ncorrelation2', ' cflvsc.FAPcorrelation2',\n",
    "       ' cflvsc.ebv', ' cflvsc.ebverr',\n",
    "       ' cflvsc.FreqKfi2', ' cflvsc.HeightKfi2',\n",
    "       ' cflvsc.FreqLfl2', ' cflvsc.HeightLfl2',\n",
    "       ' cflvsc.FreqLSG', ' cflvsc.HeightLSG',\n",
    "       ' cflvsc.FreqPDM', ' cflvsc.HeightPDM',\n",
    "       ' cflvsc.FreqSTR', ' cflvsc.HeightSTR',\n",
    "       ' cflvsc.Avar']].to_numpy()\n",
    "\n",
    "#Maybe flag objects with low Ncorrelation with a different MainVarType flag - that was it can identify them as bad\n",
    "\n",
    "X=data[[' cflvsc.zAperMag3',' cflvsc.yAperMag3',' cflvsc.jAperMag3', ' cflvsc.hAperMag3',\n",
    "        ' cflvsc.ksAperMag3',\n",
    "       ' cflvsc.FreqKfi2',' cflvsc.FreqLfl2',' cflvsc.FreqLSG',' cflvsc.FreqPDM',\n",
    "       ' cflvsc.FreqSTR',\n",
    "       ' cflvsc.Avar',' cflvsc.Kfi2', ' cflvsc.L2',' cflvsc.ebv'\n",
    "       ]].to_numpy()\n",
    "\n",
    "dX = data[[' cflvsc.zAperMag3Err', ' cflvsc.yAperMag3Err',' cflvsc.jAperMag3Err',' cflvsc.hAperMag3Err', \n",
    "           ' cflvsc.ksAperMag3Errs',\n",
    "        'InverseHeightKfi2','InverseHeightLfl2','InverseHeightLSG','InverseHeightPDM',\n",
    "        'InverseHeightSTR',\n",
    "           'zeroes','zeroes','zeroes',' cflvsc.ebverr'\n",
    "          ]].to_numpy()\n",
    "\n",
    "#dX = data[[' cflvsc.zAperMag3Err', ' cflvsc.yAperMag3Err',' cflvsc.jAperMag3Err',' cflvsc.hAperMag3Err', \n",
    "#           ' cflvsc.ksAperMag3Errs',\n",
    "#        ' cflvsc.HeightKfi2',' cflvsc.HeightLfl2',' cflvsc.HeightLSG',' cflvsc.HeightPDM',\n",
    "#        ' cflvsc.HeightSTR',\n",
    "#           'zeroes','zeroes','zeroes',' cflvsc.ebverr','zeroes'\n",
    "#          ]].to_numpy()\n",
    "\n",
    "y=data[' cflvsc.MainVarType'].to_numpy()\n",
    "print(X)\n",
    "print(y)\n",
    "\n",
    "n_objects = X.shape[0]\n",
    "n_features = X.shape[1]\n",
    "print(n_objects, 'objects,', n_features, 'features')\n",
    "\n",
    "shuffled_inds = numpy.random.choice(numpy.arange(n_objects),n_objects,replace=False)\n",
    "print(\"Shuffled Indices: \", shuffled_inds)\n",
    "print(len(shuffled_inds))\n",
    "shuffled_inds = numpy.random.choice(shuffled_inds,len(shuffled_inds),replace=False)\n",
    "print(\"Re-Shuffled Indices? \", shuffled_inds)\n",
    "n_train = 20000\n",
    "n_test = 2000\n",
    "print('Train set size = {}, Test set size = {}'.format(n_train, n_test))\n",
    "\n",
    "nf = n_features\n",
    "train_inds = shuffled_inds[:n_train]\n",
    "X_train = X[train_inds][:,:nf]\n",
    "y_train = y[train_inds]\n",
    "dX_train = dX[train_inds][:,:nf]\n",
    "\n",
    "test_inds = shuffled_inds[n_train:(n_train + n_test)]\n",
    "X_test = X[test_inds][:,:nf]\n",
    "y_test = y[test_inds]\n",
    "dX_test = dX[test_inds][:,:nf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRF: 0.737\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer as Imputer # for new versions for sklearn\n",
    "\n",
    "n_trees = 100\n",
    "prf_cls = PRF.prf(n_estimators=n_trees,  bootstrap=True)\n",
    "prf_cls.fit(X=X_train, y=y_train, dX = dX_train)\n",
    "#prf_cls.score(X_test, y=y_test)\n",
    "print('PRF: {}'.format(prf_cls.score(X_test, y=y_test, dX=dX_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.738 [array([0.    , 0.    , 0.    , 0.    , 0.    , 0.0045, 0.0055, 0.0605,\n",
      "       0.015 , 0.0045, 0.169 , 0.011 , 0.0365, 0.0405]), array([0.    , 0.    , 0.    , 0.    , 0.    , 0.0065, 0.01  , 0.0665,\n",
      "       0.0155, 0.0025, 0.165 , 0.013 , 0.0285, 0.0445]), array([0.    , 0.    , 0.    , 0.    , 0.    , 0.0075, 0.011 , 0.0645,\n",
      "       0.016 , 0.0015, 0.1615, 0.008 , 0.031 , 0.036 ]), array([0.    , 0.    , 0.    , 0.    , 0.    , 0.0085, 0.0165, 0.0625,\n",
      "       0.0225, 0.003 , 0.163 , 0.0085, 0.028 , 0.046 ]), array([0.    , 0.    , 0.    , 0.    , 0.    , 0.007 , 0.0075, 0.061 ,\n",
      "       0.016 , 0.0005, 0.166 , 0.0135, 0.0315, 0.036 ])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.    , 0.    , 0.    , 0.    , 0.    , 0.0068, 0.0101, 0.063 ,\n",
       "       0.017 , 0.0024, 0.1649, 0.0108, 0.0311, 0.0406])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ... load data, define score function\n",
    "def score(X, y):\n",
    "    y_pred = predict(X)\n",
    "    return accuracy(y, y_pred)\n",
    "\n",
    "base_score, score_decreases = get_score_importances(prf_cls.score, X_test, y_test)\n",
    "print(base_score, score_decreases)\n",
    "feature_importances = numpy.mean(score_decreases, axis=0)\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-50f948107776>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mactual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pred' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report \n",
    "  \n",
    "actual = y_test\n",
    "predicted = pred \n",
    "results = confusion_matrix(actual, predicted) \n",
    "  \n",
    "print ('Confusion Matrix :')\n",
    "print (results) \n",
    "print ('Accuracy Score :',accuracy_score(actual, predicted))\n",
    "print ('Report : ',classification_report(actual, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraction of nans in X: 0.033\n",
      "PRF: 0.753\n",
      "RF: 0.748\n",
      "PRF: 0.735\n"
     ]
    }
   ],
   "source": [
    "nof_nans = numpy.sum(numpy.isnan(X_test))\n",
    "print('fraction of nans in X: {:.3f}'.format(nof_nans/numpy.prod(X_train.shape)))\n",
    "    \n",
    "prf_cls = PRF.prf(n_estimators=n_trees,  bootstrap=True)\n",
    "prf_cls.fit(X=X_train, y=y_train)\n",
    "print('PRF: {}'.format(prf_cls.score(X=X_test, y=y_test)))\n",
    "\n",
    "imp = Imputer(missing_values=numpy.nan, strategy='median')\n",
    "X_train_w_nans_imp = imp.fit_transform(X_train)\n",
    "X_test_w_nans_imp = imp.fit_transform(X_test)\n",
    "dX_train_w_nans_imp = imp.fit_transform(dX_train)\n",
    "dX_test_w_nans_imp = imp.fit_transform(dX_test)\n",
    "\n",
    "RF = RandomForestClassifier(n_estimators=n_trees,n_jobs=-1, bootstrap=True)\n",
    "RF.fit(X_train_w_nans_imp, y_train)\n",
    "print('RF: {}'.format(RF.score(X_test_w_nans_imp,y_test)))\n",
    "\n",
    "prf_cls = PRF.prf(n_estimators=n_trees,  bootstrap=True)\n",
    "prf_cls.fit(X=X_train_w_nans_imp, y=y_train, dX=dX_train_w_nans_imp)\n",
    "print('PRF: {}'.format(prf_cls.score(X=X_test_w_nans_imp, y=y_test, dX=dX_test_w_nans_imp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14.76163  14.657574 14.700644 ...  1.425342  0.       82.      ]\n",
      " [      nan       nan       nan ...  5.70632   0.       84.      ]\n",
      " [      nan       nan       nan ...  1.16128   0.       84.      ]\n",
      " ...\n",
      " [      nan       nan       nan ...  0.561949  1.122712 74.      ]\n",
      " [      nan       nan       nan ... 16.451157  1.941331 65.      ]\n",
      " [      nan       nan       nan ... 44.133835  1.918944 58.      ]]\n",
      "['  RR' '  RR' '  RR' ... '  E' '  EB' '  EA']\n",
      "174359 objects, 15 features\n",
      "Re-Shuffled Indices?  [114451 162681   4658 ... 148918 140746  19042]\n",
      "Train set size = 10000, Test set size = 1000\n"
     ]
    }
   ],
   "source": [
    "data = data[data[' cflvsc.MainVarType'] != 'Spurious']\n",
    "\n",
    "for inverse_column in [' cflvsc.HeightKfi2',' cflvsc.HeightLfl2',' cflvsc.HeightLSG',' cflvsc.HeightPDM',\n",
    "        ' cflvsc.HeightSTR']:\n",
    "    columnName = inverse_column.replace(\" cflvsc.\",'Inverse')\n",
    "    data[columnName] = numpy.ones(len(data[inverse_column]))\n",
    "    data[columnName] = data[columnName].div(data[inverse_column])\n",
    "\n",
    "#Maybe flag objects with low Ncorrelation with a different MainVarType flag - that was it can identify them as bad\n",
    "\n",
    "X=data[[' cflvsc.zAperMag3',' cflvsc.yAperMag3',' cflvsc.jAperMag3', ' cflvsc.hAperMag3',\n",
    "        ' cflvsc.ksAperMag3',\n",
    "       ' cflvsc.FreqKfi2',' cflvsc.FreqLfl2',' cflvsc.FreqLSG',' cflvsc.FreqPDM',\n",
    "       ' cflvsc.FreqSTR',\n",
    "       ' cflvsc.Avar',' cflvsc.Kfi2', ' cflvsc.L2',' cflvsc.ebv',' cflvsc.Ngoodmeasures',\n",
    "       ]].to_numpy()\n",
    "\n",
    "dX = data[[' cflvsc.zAperMag3Err', ' cflvsc.yAperMag3Err',' cflvsc.jAperMag3Err',' cflvsc.hAperMag3Err', \n",
    "           ' cflvsc.ksAperMag3Errs',\n",
    "        'InverseHeightKfi2','InverseHeightLfl2','InverseHeightLSG','InverseHeightPDM',\n",
    "        'InverseHeightSTR',\n",
    "           'zeroes','zeroes','zeroes',' cflvsc.ebverr','zeroes'\n",
    "          ]].to_numpy()\n",
    "\n",
    "y=data[' cflvsc.MainVarType'].to_numpy()\n",
    "print(X)\n",
    "print(y)\n",
    "\n",
    "n_objects = X.shape[0]\n",
    "n_features = X.shape[1]\n",
    "print(n_objects, 'objects,', n_features, 'features')\n",
    "\n",
    "shuffled_inds = numpy.random.choice(numpy.arange(n_objects),n_objects,replace=False)\n",
    "shuffled_inds = numpy.random.choice(shuffled_inds,len(shuffled_inds),replace=False)\n",
    "print(\"Re-Shuffled Indices? \", shuffled_inds)\n",
    "n_train = 10000\n",
    "n_test = 1000\n",
    "print('Train set size = {}, Test set size = {}'.format(n_train, n_test))\n",
    "\n",
    "nf = n_features\n",
    "train_inds = shuffled_inds[:n_train]\n",
    "X_train = X[train_inds][:,:nf]\n",
    "y_train = y[train_inds]\n",
    "dX_train = dX[train_inds][:,:nf]\n",
    "\n",
    "test_inds = shuffled_inds[n_train:(n_train + n_test)]\n",
    "X_test = X[test_inds][:,:nf]\n",
    "y_test = y[test_inds]\n",
    "dX_test = dX[test_inds][:,:nf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRF: 0.739\n"
     ]
    }
   ],
   "source": [
    "n_trees = 100\n",
    "prf_cls = PRF.prf(n_estimators=n_trees,  bootstrap=True)\n",
    "prf_cls.fit(X=X_train, y=y_train, dX = dX_train)\n",
    "print('PRF: {}'.format(prf_cls.score(X_test, y=y_test, dX=dX_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing values\n",
    "* the original data does not have missing values. We add missing values to the data by setting in random elements in X to numpy.nan\n",
    "* we compare the results to the original RF where the missing values are imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer as Imputer # for new versions for sklearn\n",
    "#from sklearn.preprocessing import Imputer # old versions of sklearn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def insert_nans(X_train, X_test, nan_frac):\n",
    "    X_train_w_nans = X_train.copy()\n",
    "    X_test_w_nans = X_test.copy()\n",
    "\n",
    "    nof_nans = int( numpy.prod(X_train.shape) * nan_frac )\n",
    "    for i in range(nof_nans):\n",
    "        o = numpy.random.choice(n_train)\n",
    "        f = numpy.random.choice(nf)\n",
    "        X_train_w_nans[o,f] = numpy.nan\n",
    "\n",
    "    nof_nans = int( numpy.prod(X_test.shape) * nan_frac )\n",
    "    for i in range(nof_nans):\n",
    "        o = numpy.random.choice(n_test)\n",
    "        f = numpy.random.choice(nf)\n",
    "        X_test_w_nans[o,f] = numpy.nan\n",
    "    \n",
    "    imp = Imputer(missing_values=numpy.nan, strategy='median')\n",
    "    X_train_w_nans_imp = imp.fit_transform(X_train_w_nans)\n",
    "    X_test_w_nans_imp = imp.fit_transform(X_test_w_nans)\n",
    "    \n",
    "    return X_train_w_nans, X_test_w_nans, X_train_w_nans_imp, X_test_w_nans_imp\n",
    "\n",
    "def prf_rf_nans_compare_single(X_train, X_test, n_trees, nan_frac):\n",
    "    \n",
    "    X_train_w_nans, X_test_w_nans, X_train_w_nans_imp, X_test_w_nans_imp = insert_nans(X_train, X_test, nan_frac)\n",
    "\n",
    "    nof_nans = numpy.sum(numpy.isnan(X_train_w_nans))\n",
    "    print('fraction of nans in X: {:.3f}'.format(nof_nans/numpy.prod(X_train.shape)))\n",
    "    \n",
    "    print('Accuracy for {} trees --- '.format(n_trees))\n",
    "\n",
    "    prf_cls = PRF.prf(n_estimators=n_trees,  bootstrap=True)\n",
    "    prf_cls.fit(X=X_train_w_nans, y=y_train)\n",
    "    print('PRF: {}'.format(prf_cls.score(X=X_test_w_nans, y=y_test)))\n",
    "\n",
    "    RF = RandomForestClassifier(n_estimators=n_trees,n_jobs=-1, bootstrap=True)\n",
    "    RF.fit(X_train, y_train)\n",
    "    print('RF: {}'.format(RF.score(X_test_w_nans_imp,y_test)))\n",
    "    \n",
    "    return\n",
    "\n",
    "def plot_prf_rf_cmpr(nan_frac_vec_true, prf_scores, prf_scores_stds, rf_scores, rf_scores_stds):\n",
    "    plt.figure(figsize = (10,7))\n",
    "    lw = 7\n",
    "    alpha = 0.5\n",
    "    alpha_eb = 0.3\n",
    "    ms = 25\n",
    "    \n",
    "    markers, caps, bars =plt.errorbar(x=nan_frac_vec_true,y=prf_scores,yerr=prf_scores_stds,capsize=10, label = 'PRF',fmt ='--*', markersize= 15, capthick=3)\n",
    "    [bar.set_alpha(alpha_eb) for bar in bars]\n",
    "    markers, caps, bars =plt.errorbar(x=nan_frac_vec_true,y=rf_scores,yerr=rf_scores_stds,capsize=10,label = 'RF',fmt ='--*', markersize= 15, capthick=3)\n",
    "    [bar.set_alpha(alpha_eb) for bar in bars]\n",
    "\n",
    "    plt.legend(fontsize = 20)\n",
    "    plt.xlabel('Fraction of NaNs in X', fontsize = 20)\n",
    "    plt.ylabel('Accuracy', fontsize = 20)\n",
    "    plt.xticks(fontsize = 20)\n",
    "    yticks = plt.gca().get_yticks()\n",
    "    yticks_p = ['{}%'.format('%.1f' % (yt*100)) for yt in yticks]\n",
    "    plt.yticks(yticks, yticks_p, fontsize = 20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return\n",
    "\n",
    "def prf_rf_nans_compare_full(X_train, X_test, n_itr, n_trees):\n",
    "\n",
    "    nof_elements = numpy.prod(X_train.shape)\n",
    "    \n",
    "    prf_scores = []\n",
    "    prf_scores_stds = []\n",
    "    rf_scores = []\n",
    "    rf_scores_stds = []\n",
    "\n",
    "    nan_frac_vec = [0, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.8, 1.1, 1.5, 2]\n",
    "    nan_frac_vec_true = numpy.zeros(len(nan_frac_vec))\n",
    "    for n_idx, nan_frac in enumerate(nan_frac_vec):\n",
    "\n",
    "        X_train_w_nans, X_test_w_nans, X_train_w_nans_imp, X_test_w_nans_imp = insert_nans(X_train, X_test, nan_frac)\n",
    "\n",
    "        scores = numpy.zeros(n_itr)\n",
    "        for i in range(n_itr): \n",
    "            prf_cls = PRF.prf(n_estimators=n_trees,  bootstrap=True, keep_proba=0.01)\n",
    "            prf_cls.fit(X=X_train_w_nans, y=y_train)\n",
    "            scores[i] = prf_cls.score(X=X_test_w_nans, y=y_test)\n",
    "        prf_scores += [scores.mean()]\n",
    "        prf_scores_stds += [scores.std()]\n",
    "\n",
    "        scores = numpy.zeros(n_itr)\n",
    "        for i in range(n_itr): \n",
    "            RF = RandomForestClassifier(n_estimators=n_trees,n_jobs=-1, bootstrap=True)\n",
    "            RF.fit(X_train_w_nans_imp, y_train)\n",
    "            scores[i] = RF.score(X_test_w_nans_imp,y_test)\n",
    "        rf_scores += [scores.mean()]\n",
    "        rf_scores_stds += [scores.std()]\n",
    "        \n",
    "        nof_nans = numpy.sum(numpy.isnan(X_train_w_nans))\n",
    "        nan_frac_vec_true[n_idx] = nof_nans/nof_elements\n",
    "\n",
    "        print('nan fraction:{:.2f}, PRF:{:.3f}, RF:{:.3f}'.format(nan_frac_vec_true[n_idx],prf_scores[-1], rf_scores[-1]))\n",
    "        \n",
    "\n",
    "    \n",
    "    plot_prf_rf_cmpr(nan_frac_vec_true, prf_scores, prf_scores_stds, rf_scores, rf_scores_stds)\n",
    "    \n",
    "    return nan_frac_vec_true, prf_scores, rf_scores, prf_scores_stds, rf_scores_stds\n",
    "\n",
    "\n",
    "def prf_rf_nans_test_set_only_compare_full(X_train, X_test, n_itr, n_trees):\n",
    "\n",
    "    nof_elements = numpy.prod(X_train.shape)\n",
    "    \n",
    "    prf_scores = []\n",
    "    prf_scores_stds = []\n",
    "    rf_scores = []\n",
    "    rf_scores_stds = []\n",
    "\n",
    "    nan_frac_vec = [0, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.8, 1.1, 1.5, 2]\n",
    "    nan_frac_vec_true = numpy.zeros(len(nan_frac_vec))\n",
    "    for n_idx, nan_frac in enumerate(nan_frac_vec):\n",
    "\n",
    "        X_train_w_nans, X_test_w_nans, X_train_w_nans_imp, X_test_w_nans_imp = insert_nans(X_train, X_test, nan_frac)\n",
    "\n",
    "        scores = numpy.zeros(n_itr)\n",
    "        for i in range(n_itr): \n",
    "            prf_cls = PRF.prf(n_estimators=n_trees,  bootstrap=True, keep_proba=0.01)\n",
    "            prf_cls.fit(X=X_train, y=y_train)\n",
    "            scores[i] = prf_cls.score(X=X_test_w_nans, y=y_test)\n",
    "        prf_scores += [scores.mean()]\n",
    "        prf_scores_stds += [scores.std()]\n",
    "\n",
    "        scores = numpy.zeros(n_itr)\n",
    "        for i in range(n_itr): \n",
    "            RF = RandomForestClassifier(n_estimators=n_trees,n_jobs=-1, bootstrap=True)\n",
    "            RF.fit(X_train, y_train)\n",
    "            scores[i] = RF.score(X_test_w_nans_imp,y_test)\n",
    "        rf_scores += [scores.mean()]\n",
    "        rf_scores_stds += [scores.std()]\n",
    "        \n",
    "        nof_nans = numpy.sum(numpy.isnan(X_train_w_nans))\n",
    "        nan_frac_vec_true[n_idx] = nof_nans/nof_elements\n",
    "\n",
    "        print('nan fraction:{:.2f}, PRF:{:.3f}, RF:{:.3f}'.format(nan_frac_vec_true[n_idx],prf_scores[-1], rf_scores[-1]))\n",
    "        \n",
    "\n",
    "    plot_prf_rf_cmpr(nan_frac_vec_true, prf_scores, prf_scores_stds, rf_scores, rf_scores_stds)\n",
    "    \n",
    "    return nan_frac_vec_true, prf_scores, rf_scores, prf_scores_stds, rf_scores_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = prf_rf_nans_compare_single(X_train=X_train, X_test=X_test, n_trees=1, nan_frac=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = prf_rf_nans_compare_single(X_train=X_train, X_test=X_test, n_trees=10, nan_frac=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = prf_rf_nans_compare_single(X_train=X_train, X_test=X_test, n_trees=100, nan_frac=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing values in both train and test sets\n",
    "* The PRF accuracy is higher for a single tree, but the same as a regular RF for a large number of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = prf_rf_nans_compare_full(X_train=X_train, X_test=X_test, n_itr=10, n_trees=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = prf_rf_nans_compare_full(X_train=X_train, X_test=X_test, n_itr = 1, n_trees = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing values in test set only\n",
    "* The PRF accuracy is higher even for a large number of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = prf_rf_nans_test_set_only_compare_full(X_train=X_train, X_test=X_test, n_itr = 10, n_trees = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = prf_rf_nans_test_set_only_compare_full(X_train=X_train, X_test=X_test, n_itr = 5, n_trees = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = prf_rf_nans_test_set_only_compare_full(X_train=X_train, X_test=X_test, n_itr = 1, n_trees = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
